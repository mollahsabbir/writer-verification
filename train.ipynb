{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models\n",
    "import importlib\n",
    "importlib.reload(models)\n",
    "from models import ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_HEIGHT = 100\n",
    "INPUT_WIDTH = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3\n",
    "EMBEDDING_SIZE = 1024\n",
    "CLASSES = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_channels = NUM_CHANNELS\n",
    "                , classes = CLASSES\n",
    "                , embedding_size = EMBEDDING_SIZE\n",
    "                , inference = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img = torch.rand(1,3, INPUT_HEIGHT, INPUT_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 0.0061, 0.0000, 0.0053, 0.0172],\n",
      "          [0.0028, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0062, 0.0031, 0.0121, 0.0109, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0035, 0.0077, 0.0010, 0.0000],\n",
      "          [0.0171, 0.0071, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0361, 0.0021, 0.0032, 0.0000]],\n",
      "\n",
      "         [[0.1181, 0.1172, 0.1178, 0.1103, 0.1125],\n",
      "          [0.1217, 0.1250, 0.1291, 0.1290, 0.1141],\n",
      "          [0.1163, 0.1130, 0.0942, 0.1144, 0.1215],\n",
      "          ...,\n",
      "          [0.1238, 0.1154, 0.1084, 0.1143, 0.1218],\n",
      "          [0.1265, 0.1188, 0.1060, 0.1348, 0.1186],\n",
      "          [0.1227, 0.1135, 0.1202, 0.1248, 0.1036]],\n",
      "\n",
      "         [[0.0178, 0.0242, 0.0460, 0.0161, 0.0291],\n",
      "          [0.0317, 0.0155, 0.0202, 0.0133, 0.0111],\n",
      "          [0.0127, 0.0252, 0.0244, 0.0140, 0.0000],\n",
      "          ...,\n",
      "          [0.0212, 0.0252, 0.0405, 0.0066, 0.0236],\n",
      "          [0.0362, 0.0113, 0.0257, 0.0377, 0.0611],\n",
      "          [0.0123, 0.0241, 0.0195, 0.0220, 0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0309, 0.0228, 0.0496, 0.0337, 0.0312],\n",
      "          [0.0158, 0.0140, 0.0234, 0.0291, 0.0240],\n",
      "          [0.0445, 0.0133, 0.0181, 0.0312, 0.0056],\n",
      "          ...,\n",
      "          [0.0383, 0.0273, 0.0324, 0.0096, 0.0266],\n",
      "          [0.0486, 0.0093, 0.0301, 0.0294, 0.0294],\n",
      "          [0.0543, 0.0256, 0.0198, 0.0143, 0.0275]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0455, 0.0233, 0.0289, 0.0286, 0.0336],\n",
      "          [0.0516, 0.0476, 0.0570, 0.0305, 0.0523],\n",
      "          [0.0368, 0.0581, 0.0454, 0.0498, 0.0350],\n",
      "          ...,\n",
      "          [0.0666, 0.0397, 0.0431, 0.0339, 0.0257],\n",
      "          [0.0546, 0.0386, 0.0346, 0.0431, 0.0150],\n",
      "          [0.0422, 0.0454, 0.0352, 0.0219, 0.0398]]]],\n",
      "       grad_fn=<MaxPool2DWithIndicesBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample_img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'embedding_size': EMBEDDING_SIZE,\n",
    "            'classes': CLASSES,\n",
    "            'num_channels': NUM_CHANNELS,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            }, \"saved_models/random.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b385135f24cd8557ac1c14401f016e5516e3c1c226c453fa3f7e40284f0acb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
